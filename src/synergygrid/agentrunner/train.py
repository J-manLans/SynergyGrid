import gymnasium as gym
import datetime
from pathlib import Path
from stable_baselines3.common.monitor import Monitor
from synergygrid.agentrunner import AgentRunner
from synergygrid.config import environment


# TODO: this only accompanies the stable baselines3 models as of now. We need to crete a more
# modular agent base class that can accompany many different models
def train_agent(
    runner: AgentRunner,
    continue_training=False,
    agent_steps="",
    timesteps=20000,
    iterations=10,
):
    """
    Train an agent, either from scratch or by continuing from a saved checkpoint.

    :param continue_training: If True, the training continues from an existing model checkpoint.
    :type continue_training: bool
    :param agent_steps: The specific checkpoint steps of the model to continue training from.
    :type agent_steps: str
    :param timesteps: Number of steps to train before saving the agent.
    :type timesteps: int
    :param iterations: Number of training loops, each consisting of `timesteps` steps.
    :type iterations: int
    """

    # Get current date and time for unique file naming
    date = datetime.datetime.now().strftime("%y-%m-%d_%H-%M-%S")

    # Create directories for saving models and logs
    model_dir = Path("results/models") / runner.environment
    log_dir = Path("results/logs") / runner.environment

    Path(model_dir).mkdir(parents=True, exist_ok=True)
    Path(log_dir).mkdir(parents=True, exist_ok=True)

    # Create and wrap the training environment
    env = gym.make(runner.environment, render_mode=None)
    # Wrap the environment with a Monitor for logging.
    # The created csv is needed for plotting our own graphs with matplotlib later.
    monitor_file = Path(log_dir) / f"{runner.environment}_{runner.algorithm}_{date}.csv"
    env = Monitor(env, filename=str(monitor_file))

    model = None
    if continue_training:
        print("Loading existing training data")
        # Get the model with the desired steps to continue its training
        model = runner.get_model(agent_steps, env)
    else:
        # Initialize a fresh model
        model = runner.AlgorithmClass(
            env=env,
            verbose=1,
            tensorboard_log=log_dir,
            **environment.get(runner.environment, {}),
        )

    try:
        # This loop will keep training based on timesteps and iterations.
        # After the timesteps are completed, the model is saved and training
        # continues for the next iteration. When training is done, start another
        # cmd prompt and launch Tensorboard:
        # tensorboard --logdir results/logs/<env_name>
        # Once Tensorboard is loaded, it will print a URL. Follow the URL to see
        # the status of the training.
        for i in range(1, iterations + 1):
            print(
                f"\nTraining starting for iteration: {i}, environment: {runner.environment}\n"
            )

            # Train the model
            model.learn(
                total_timesteps=timesteps,
                tb_log_name=f"{date} {runner.algorithm}",
                reset_num_timesteps=False,
            )

            # Save the model
            save_path = (
                Path(model_dir)
                / f"{runner.algorithm}_{runner.environment}_{model.num_timesteps}_{date}"
            )
            model.save(save_path)
            print(f"\nModel saved with {model.num_timesteps} time steps")
    finally:
        env.close()
